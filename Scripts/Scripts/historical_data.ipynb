{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IB connected to 127.0.0.1:7497 clientId=17>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "util.startLoop()  \n",
    "\n",
    "ib = IB()\n",
    "ib.client.setConnectOptions('+PACEAPI')\n",
    "ib.connect('127.0.0.1', 7497, clientId=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yahoo_fin.stock_info as si\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import os.path\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def GetInputs(inputs_path):\n",
    "    df = pd.read_csv(inputs_path, header= None)\n",
    "    df_dict = dict(zip(df[0], df[1]))\n",
    "    df_dict['symbols'] = df_dict['symbols'].split(\"|\")\n",
    "    return df_dict\n",
    "\n",
    "\n",
    "def CreateFolderIfFolderDoesntExist(symbol, data_path, symbol_kind):\n",
    "    folder_path = data_path + \"/\" + symbol_kind + \"/\" + symbol\n",
    "    folder_exist = os.path.exists(folder_path)\n",
    "    if not folder_exist:\n",
    "        os.mkdir(folder_path)\n",
    "        print(\"created folder for \", folder_path)\n",
    "\n",
    "\n",
    "def GetDurationOfDataNeeded(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['date_time'] = pd.to_datetime(df['date'])\n",
    "    most_recent_date = df['date_time'].max()\n",
    "    now = dt.datetime.now()\n",
    "    return (now - most_recent_date)\n",
    "\n",
    "def GetTimeIncrement(interval_time):\n",
    "    if interval_time == \"10 mins\":\n",
    "        return dt.timedelta(seconds = 600)\n",
    "    elif interval_time == \"1 hour\":\n",
    "        return dt.timedelta(seconds = 3600)\n",
    "    elif interval_time == \"1 day\":\n",
    "        return dt.timedelta(days = 1)\n",
    "\n",
    "\n",
    "def UpdatePriceFiles(symbol, data_path, symbol_kind, interval_time_list):\n",
    "    contract = Stock(symbol, 'SMART', 'USD')\n",
    "    ib.qualifyContracts(contract)\n",
    "    for interval_time in interval_time_list:\n",
    "        time_increment = GetTimeIncrement(interval_time)\n",
    "        interval_time_string = interval_time.replace(\" \", \"_\")\n",
    "        file_path = data_path + \"/\" + symbol_kind + \"/\" + symbol + \"/\" + interval_time_string + \".csv\"\n",
    "        file_exist = os.path.exists(file_path)\n",
    "        duration_time = '365 D'\n",
    "        if file_exist:\n",
    "            time_since_last_data_stored = GetDurationOfDataNeeded(file_path)\n",
    "            if time_since_last_data_stored > time_increment:\n",
    "                duration_time = str(time_since_last_data_stored.days + 1) + \" D\"\n",
    "                bars = ib.reqHistoricalData(\n",
    "                        contract,\n",
    "                        endDateTime='',\n",
    "                        durationStr=duration_time,\n",
    "                        barSizeSetting=interval_time,\n",
    "                        whatToShow='TRADES',\n",
    "                        useRTH=True,\n",
    "                        formatDate=1)\n",
    "                existing_data_df = pd.read_csv(file_path)\n",
    "                existing_data_df = existing_data_df.drop(existing_data_df.filter(regex='Unnamed').columns, axis=1)\n",
    "                new_data_df = util.df(bars)\n",
    "                merged_df = pd.concat([existing_data_df,new_data_df]).drop_duplicates().reset_index(drop=True)\n",
    "                merged_df = merged_df.drop_duplicates(subset='date', keep=\"last\")\n",
    "                merged_df = merged_df.dropna()\n",
    "                merged_df.to_csv(file_path)\n",
    "                print(\"Added data to \", symbol, interval_time)\n",
    "        else:\n",
    "            bars = ib.reqHistoricalData(\n",
    "                    contract,\n",
    "                    endDateTime='',\n",
    "                    durationStr=duration_time,\n",
    "                    barSizeSetting=interval_time,\n",
    "                    whatToShow='TRADES',\n",
    "                    useRTH=True,\n",
    "                    formatDate=1)\n",
    "            df = util.df(bars)\n",
    "            df.to_csv(file_path)\n",
    "            print(\"Created new file for \", symbol, interval_time)\n",
    "    return\n",
    "\n",
    "def UpdateEarningsFile(symbol, data_path, symbol_kind):\n",
    "    file_path = data_path + \"/\" + symbol_kind + \"/\" + symbol + \"/earnings.csv\"\n",
    "    file_exist = os.path.exists(file_path)\n",
    "    if file_exist:\n",
    "        filetime = dt.datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "        if filetime.date() == dt.date.today():\n",
    "            return\n",
    "\n",
    "    else:\n",
    "        earnings_dict = si.get_earnings_history(symbol)\n",
    "        df_earnings = pd.DataFrame(earnings_dict)\n",
    "        earnings_dates_list = pd.to_datetime(df_earnings.startdatetime).dt.date.to_list()\n",
    "        earnings_dates_list = [earning_date for earning_date in earnings_dates_list if earning_date <= dt.date.today()]\n",
    "        df = pd.DataFrame({\"date\" :earnings_dates_list})\n",
    "        df.to_csv(file_path)\n",
    "        print(\"Updated file for earnings for\", symbol)\n",
    "    return\n",
    "\n",
    "def UpdateOccFiles(symbol, data_path, symbol_kind):\n",
    "    file_path = data_path + \"/\" + symbol_kind + \"/\" + symbol + \"/occ.csv\"\n",
    "    file_exist = os.path.exists(file_path)\n",
    "    if file_exist:\n",
    "        filetime = dt.datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "        if filetime.date() == dt.date.today():\n",
    "            return\n",
    "    else:\n",
    "        tod = dt.date.today()\n",
    "        url = 'https://marketdata.theocc.com/series-search?symbolType=U&symbol='+symbol\n",
    "        r = requests.get(url)\n",
    "        li = r.text.splitlines()\n",
    "        list_opt = []\n",
    "        for x in range(7,len(li)-1):\n",
    "            lin=li[x]\n",
    "            myli=lin.split()\n",
    "            k = float(myli[4] + \".\" + myli[5])\n",
    "            exp = dt.date(int(myli[1]),int(myli[2]),int(myli[3]))\n",
    "            if exp>=tod and exp <= tod + relativedelta(months=4) and (k*10)%5==0:\n",
    "                list_opt.append( {'exp': exp.strftime('%Y%m%d'), 'k': str(k)} )\n",
    "        df_opt = pd.DataFrame(list_opt)\n",
    "        df_opt = df_opt.groupby('exp').filter(lambda x: len(x)>8)\n",
    "        df_opt.to_csv(file_path)\n",
    "        print(\"Updated file for occ for\", symbol)\n",
    "    return\n",
    "\n",
    "def UpdateData(symbol, data_path, symbol_kind, interval_time_list):\n",
    "    CreateFolderIfFolderDoesntExist(symbol, data_path, symbol_kind)\n",
    "    UpdatePriceFiles(symbol, data_path, symbol_kind, interval_time_list)\n",
    "    UpdateEarningsFile(symbol, data_path, symbol_kind)\n",
    "    UpdateOccFiles(symbol, data_path, symbol_kind)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added data to  AAPL 1 hour\n",
      "Added data to  AAPL 10 mins\n",
      "Updated file for occ for AAPL\n",
      "Added data to  MSFT 1 day\n",
      "Added data to  MSFT 1 hour\n",
      "Added data to  MSFT 10 mins\n",
      "Updated file for occ for MSFT\n",
      "Added data to  AMZN 1 day\n",
      "Added data to  AMZN 1 hour\n",
      "Added data to  AMZN 10 mins\n",
      "Updated file for occ for AMZN\n",
      "Added data to  META 1 day\n",
      "Added data to  META 1 hour\n",
      "Added data to  META 10 mins\n",
      "Updated file for occ for META\n",
      "Added data to  TSLA 1 day\n",
      "Added data to  TSLA 1 hour\n",
      "Added data to  TSLA 10 mins\n",
      "Updated file for occ for TSLA\n",
      "Added data to  OXY 1 day\n",
      "Added data to  OXY 1 hour\n",
      "Added data to  OXY 10 mins\n",
      "Updated file for occ for OXY\n"
     ]
    }
   ],
   "source": [
    "inputs_path = \"./../../Inputs/historical_data_inputs.csv\"\n",
    "data_path = \"./../../HistoricalData\"\n",
    "interval_time_list = ['1 day', '1 hour', '10 mins']\n",
    "inputs_dict = GetInputs(inputs_path)\n",
    "for symbol in inputs_dict['symbols']:\n",
    "    UpdateData(symbol, data_path, \"stocks\", interval_time_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "ib.disconnect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}